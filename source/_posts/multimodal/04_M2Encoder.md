---
title: 04_M2Encoder
tags: [multimodal,M2Encoder]
categories: [multimodal]
category_bar: true
date: 2024-07-10 15:23:16
---

M^2（M-Square）Encoder：通过大规模高效预训练来推进双语言图文理解能力。

**摘要：**虽然以CLIP为代表的VL多模态模型已经发展的很好了，但是由于大规模预训练数据集的相对匮乏导致多语言模型VLM（比如中英）发展相对较缓慢。针对这个问题，团队引入了BM-6B这个双语（中英）数据集，里面有6B多的图文对。这么多的数据训练起来很慢，团队针对这个问题提出了一种叫做分组聚合的对比损失计算方式，可以显著降低通信开销和降低GPU内存占用，训练速度提高了60%。并且他们训练得到的M2Encoder-10B在ImageNet上的zero-shot的top-1分类准确率为88.5%，ImageNet-CN上为80.7%，比之前的SOTA模型分别高2.2%和21.1%。

**可以看到加大规模的中文数据对于之前中文多模态模型有很大的提升**。

**介绍：**

BM-6B数据集的由来，中文部分是从开源数据集和合法网站上爬取的数据，然后经过清洗，数据增强等，得到了3B之多（没有说包含哪些开源中文数据集）；然后英文数据部分来自于开源英文数据集，比如LAION2B-EN，COYO-700M，Datacomp-1B，删除了可能重叠的部分，最终得到了BM（Bilingual multi-modality）-6B。







